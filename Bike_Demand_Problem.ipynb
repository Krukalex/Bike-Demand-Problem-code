{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWS+IyV4ViiAsYwOHpeXON",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krukalex/First-repo/blob/main/Bike_Demand_Problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VipdgKLdWRQS"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "qaWacfYOp3tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "wtR70EltqJcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ZhHw1FX-qO7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c bike-sharing-demand"
      ],
      "metadata": {
        "id": "ZcE58slab5kB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip bike-sharing-demand.zip"
      ],
      "metadata": {
        "id": "X_Ps_8R6cWLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "de_5G9G32bek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv('test.csv')\n",
        "train=pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "awGQkD_scgLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decision Tree"
      ],
      "metadata": {
        "id": "a9i3ikTjc2OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "EubeHbJidAMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dtypes"
      ],
      "metadata": {
        "id": "NSw0PYgqdHt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploratory analysis"
      ],
      "metadata": {
        "id": "TLPMXIPB4hwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp=train.copy()"
      ],
      "metadata": {
        "id": "X2qBJRGb450s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Demand by hour"
      ],
      "metadata": {
        "id": "dw-PNwG24lr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert date info to date time and make it index\n",
        "\n",
        "dt = pd.DatetimeIndex(exp['datetime'])\n",
        "exp.set_index(dt, inplace=True)"
      ],
      "metadata": {
        "id": "HQB2Gjyx22uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make seperate columns in data for different time denoms\n",
        "\n",
        "exp['date'] = dt.date\n",
        "exp['day'] = dt.day\n",
        "exp['month'] = dt.month\n",
        "exp['year'] = dt.year\n",
        "exp['hour'] = dt.hour\n",
        "exp['dow'] = dt.dayofweek\n",
        "exp['woy'] = dt.weekofyear"
      ],
      "metadata": {
        "id": "4leKd7uf3deV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp.head()"
      ],
      "metadata": {
        "id": "h-N19_N_65N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see how demand fluctuates over the hours of a day depending on whether or not it is a work day\n",
        "#spikes midday on weekends and during communting times on working days\n",
        "\n",
        "plt.bar(exp['hour'].unique(), exp[exp['workingday']==1].groupby('hour')['count'].sum(), color='r')\n",
        "plt.bar(exp['hour'].unique(), exp[exp['workingday']==0].groupby('hour')['count'].sum(), color='b')\n"
      ],
      "metadata": {
        "id": "OVI1b-mq3xZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Daily trend"
      ],
      "metadata": {
        "id": "SLhagaej8Edu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "is there a difference in demand between registered and casual users depending on the day of the week?"
      ],
      "metadata": {
        "id": "9Uu4Cd_m8PSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp.groupby('dow')['casual'].sum()"
      ],
      "metadata": {
        "id": "hSZlVFSz9HnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp.groupby('dow')['registered'].sum()"
      ],
      "metadata": {
        "id": "nOnDZsfL9tog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(exp['dow'].unique(), exp.groupby('dow')['casual'].sum(), color='r', width=.25)\n",
        "plt.bar(exp['dow'].unique()+.25, exp.groupby('dow')['registered'].sum(), color='b', width=.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LR53ebvm8W_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Weather"
      ],
      "metadata": {
        "id": "WE7FCZ20_QPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(exp['weather'].unique(),exp.groupby('weather')['count'].sum())"
      ],
      "metadata": {
        "id": "GNluRH-e_S7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp[exp['weather']==1][['hour', 'season']]"
      ],
      "metadata": {
        "id": "B9QCK0ubAQ-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "good weather"
      ],
      "metadata": {
        "id": "cswtXtdYEBya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "season_map = {1:'Spring', 2:'Summer', 3:'Fall', 4:'Winter'}"
      ],
      "metadata": {
        "id": "pbePrLylEWPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good_weather=exp[exp['weather']==1][['hour', 'season']].copy()\n",
        "data=pd.DataFrame({'count' : good_weather.groupby([\"hour\",\"season\"]).size()}).reset_index()\n",
        "data['season'] = data['season'].map(lambda d : season_map[d])"
      ],
      "metadata": {
        "id": "oAjkzzW19bKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.pointplot(data['hour'], data['count'], hue=data['season'])\n",
        "ax.set(xlabel='Hour Of The Day', ylabel='Good Weather Count', title=\"Good Weather By Hour Of The Day Across Season\");"
      ],
      "metadata": {
        "id": "bAGN0guWC-Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "normal weather"
      ],
      "metadata": {
        "id": "LVidbN4zEDTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal_weather=exp[exp['weather']==2][['hour', 'season']].copy()\n",
        "data2=pd.DataFrame({'count' : normal_weather.groupby([\"hour\",\"season\"]).size()}).reset_index()\n",
        "data2['season'] = data2['season'].map(lambda d : season_map[d])"
      ],
      "metadata": {
        "id": "x_-ZFYipEEnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.pointplot(data2['hour'], data2['count'], hue=data2['season'])\n",
        "ax.set(xlabel='Hour Of The Day', ylabel='Normal Weather Count', title=\"Normal Weather By Hour Of The Day Across Season\");"
      ],
      "metadata": {
        "id": "JHbIMgYLCh6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bad weather"
      ],
      "metadata": {
        "id": "QIZeIdwTF0Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_weather=exp[exp['weather']==3][['hour', 'season']].copy()\n",
        "data2=pd.DataFrame({'count' : bad_weather.groupby([\"hour\",\"season\"]).size()}).reset_index()\n",
        "data2['season'] = data2['season'].map(lambda d : season_map[d])"
      ],
      "metadata": {
        "id": "D0xYecWfF1ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.pointplot(data2['hour'], data2['count'], hue=data2['season'])\n",
        "ax.set(xlabel='Hour Of The Day', ylabel='Bad Weather Count', title=\"Bad Weather By Hour Of The Day Across Season\");"
      ],
      "metadata": {
        "id": "c82A84LqF7Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renting by hour based on weather"
      ],
      "metadata": {
        "id": "NINwLQ_UI2CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weather_map = {1:'Good', 2:'Normal', 3:'Bad', 4:'Worse'}\n",
        "renting=pd.DataFrame(exp.groupby(['weather', 'hour'],sort=True)['count'].mean()).reset_index()\n",
        "renting['weather']=renting['weather'].map(lambda d: weather_map[d])"
      ],
      "metadata": {
        "id": "95zN0Rn_GJxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "renting.head()"
      ],
      "metadata": {
        "id": "_FIvNSGIGRpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.pointplot(renting['hour'], renting['count'], hue=renting['weather'])\n",
        "ax.set(xlabel='Hour Of The Day', ylabel='Count', title=\"Renting by weather across hours\");"
      ],
      "metadata": {
        "id": "oi_oYBXjHhsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##seasons"
      ],
      "metadata": {
        "id": "VLU3QBWVLgYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renting by hour across seasons"
      ],
      "metadata": {
        "id": "EYw3hbdoI8ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.DataFrame(exp.groupby(['season', 'hour'],sort=True)['count'].mean()).reset_index()\n",
        "data['season']=data['season'].map(lambda d: season_map[d])"
      ],
      "metadata": {
        "id": "wM9FyjVmGl7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.pointplot(data['hour'], data['count'], hue=data['season'])\n",
        "ax.set(xlabel='Hour Of The Day', ylabel='Count', title=\"Renting by season across hours\");"
      ],
      "metadata": {
        "id": "JU-9CFY9JKzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Days of week"
      ],
      "metadata": {
        "id": "YVY7pTJhLjCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "timing of renting depending on day of week"
      ],
      "metadata": {
        "id": "6p8pRQJeLWxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_map = {0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}"
      ],
      "metadata": {
        "id": "vF0NpwAlLlX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.DataFrame(exp.groupby(['dow', 'hour'])['count'].mean()).reset_index()\n",
        "data['dow']=data['dow'].map(lambda d: day_map[d])"
      ],
      "metadata": {
        "id": "ZReYoaFCLp1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#more bikes are rented in mornings and evenings on weekdays and more are rented around midday on weekends\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.pointplot(data['hour'], data['count'], hue=data['dow'])\n",
        "ax.set(xlabel='Hour Of The Day', ylabel='Count', title=\"Renting by hour across days\");"
      ],
      "metadata": {
        "id": "MEbz2UnLMUtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do renting habits differ between casual and registered bikers over the course of a day?"
      ],
      "metadata": {
        "id": "gQAoSm47T2OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.DataFrame(pd.melt(exp[[\"hour\",\"casual\",\"registered\"]], id_vars=['hour'], value_vars=['casual', 'registered'], var_name='usertype', value_name='count').groupby(['usertype', 'hour'])['count'].mean()).reset_index()"
      ],
      "metadata": {
        "id": "yIl0MFkbMVUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.pointplot(data['hour'], data['count'], hue=data['usertype'])\n",
        "ax.set(xlabel='Hour of day', ylabel='Count', title='Daily renting volume of casual vs registered bikers')"
      ],
      "metadata": {
        "id": "iRu0_S2ITcyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#significantly different trends over the course of the day between caual and registered buyers\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(18,5), sharex=False, sharey=False)\n",
        "\n",
        "sns.boxplot(x='hour', y='casual', data=exp, ax=axs[0])\n",
        "axs[0].set_ylabel('casual users')\n",
        "axs[0].set_title('')\n",
        "\n",
        "sns.boxplot(x='hour', y='registered', data=exp, ax=axs[1])\n",
        "axs[1].set_ylabel('registered users')\n",
        "axs[1].set_title('');"
      ],
      "metadata": {
        "id": "leLiOQWv-i8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count variable is right skewed, and a log trasnformation makes it more normal\n",
        "plt.hist(exp['count'])\n",
        "plt.show()\n",
        "plt.hist(np.log(exp['count']))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bc2gziktSVBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp=exp.assign(log_count=lambda x:np.log(exp['count']) )"
      ],
      "metadata": {
        "id": "-eA8d0A4fVJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if you plot the log count by hour, there seems to be fewer outliers than there were with normal count\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18, 5))\n",
        "sns.boxplot(x='hour', y='log_count', data=exp, ax=ax)\n",
        "ax.set(ylabel='log(count) of Users',title='Boxplot of Log of Count grouped by hour')"
      ],
      "metadata": {
        "id": "vnyQnh7JdnSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logarithmic transformation of dependent cols\n",
        "# (adding 1 first so that 0 values don't become -inf)\n",
        "for col in ['casual', 'registered', 'count']:\n",
        "    exp['%s_log' % col] = np.log(exp[col] + 1)"
      ],
      "metadata": {
        "id": "af6h_Y_pfvxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##More rentals on workdays when mornings/evenings are warm?"
      ],
      "metadata": {
        "id": "okc77pZqDYUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "graphing a categorical variable against a continuous one, which is why we use the jitter function to make it look a bit cleaner on the graph"
      ],
      "metadata": {
        "id": "suJTaiLADezk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hour_jitter(h):\n",
        "    #return h + ((np.random.randint(low=0, high=9, size=1)[0] - 4) / 10)\n",
        "    return h + np.random.uniform(-0.4, 0.4)"
      ],
      "metadata": {
        "id": "R3tRIrtKiv21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hour_format(h):\n",
        "    return \"{:02d}:00 AM\".format(h) if h <= 12 else \"{:02d}:00 PM\".format(h%12)"
      ],
      "metadata": {
        "id": "ZchDKryLDoZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# jitter plot\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# color_map = plt.get_cmap(\"jet\")\n",
        "color_map = mcolors.ListedColormap(list([\"#5e4fa2\", \"#3288bd\", \"#66c2a5\", \"#abdda4\", \"#e6f598\", \"#fee08b\", \"#fdae61\", \"#f46d43\", \"#d53e4f\", \"#9e0142\"]))\n",
        "exp['hour_jitter'] = exp['hour'].map(hour_jitter)\n"
      ],
      "metadata": {
        "id": "BQsIAPKcDrhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#warmer mornings and evenings seem to have higher rental rates\n",
        "\n",
        "exp[exp['workingday']==1].plot(kind='scatter', x='hour_jitter', y='count', figsize=(18,6), c='temp', cmap=color_map, colorbar=True, sharex=False)\n",
        "hours = np.unique(exp['hour'].values)\n",
        "hour_labels = [hour_format(h) for h in hours]\n",
        "plt.xticks(hours, hour_labels, rotation='vertical');"
      ],
      "metadata": {
        "id": "4lIFNgjUEHeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp.drop('hour_jitter', axis=1, inplace=True);"
      ],
      "metadata": {
        "id": "jcELyjuEGEmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#once again looking at how registered users are more active during the week and casual users are more active on weekends\n",
        "\n",
        "dayOfWeek={0:'Monday', 1:'Tuesday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\n",
        "exp['weekday'] = exp['dow'].map(dayOfWeek)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15,5), sharex=False, sharey=False)\n",
        "\n",
        "sns.boxplot(x='weekday', y='registered', data=exp, ax=axs[0])\n",
        "axs[0].set_ylabel('registered users')\n",
        "axs[0].set_title('')\n",
        "\n",
        "sns.boxplot(x='weekday', y='casual', data=exp, ax=axs[1])\n",
        "axs[1].set_ylabel('casual users')\n",
        "axs[1].set_title('')\n",
        "\n",
        "exp.drop('weekday', axis=1, inplace=True);"
      ],
      "metadata": {
        "id": "7eSQW1y_ETMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confirming that bad weather substantially reduces bike rentals\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15,5), sharex=False, sharey=False)\n",
        "\n",
        "sns.boxplot('weather', 'registered', data=exp, ax=axs[0])\n",
        "sns.boxplot('weather', 'casual', data=exp, ax=axs[1])"
      ],
      "metadata": {
        "id": "H5seHA6KGhIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##looking at things like humidity, windspeed, airtemp and temperature"
      ],
      "metadata": {
        "id": "bbTaRMZJH5qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_df = exp[['count', 'registered', 'casual', 'temp', 'atemp', 'humidity', 'windspeed', 'workingday', 'holiday']]"
      ],
      "metadata": {
        "id": "OiRYKTILG3oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation matrix\n",
        "\n",
        "sub_df.corr()"
      ],
      "metadata": {
        "id": "A4kNzSMxH1ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make it prettier\n",
        "#strong correlation between temp and airtemp\n",
        "#temp correlates with rental counts of both registered and casual riders\n",
        "#windspeed has relatively low correlation\n",
        "\n",
        "corrMatt = sub_df.corr()\n",
        "mask = np.zeros_like(corrMatt)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "fig, ax = plt.subplots(figsize=(15, 6))\n",
        "sns.heatmap(corrMatt, mask=mask, vmax=.8, square=False, annot=True, ax=ax, linewidths=1);"
      ],
      "metadata": {
        "id": "VaRWheHIIFP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp['season'].reset_index()"
      ],
      "metadata": {
        "id": "d4hNMVdtK_sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Time"
      ],
      "metadata": {
        "id": "KVLnehM-KCqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "season_map = {1:'Spring', 2:'Summer', 3:'Fall', 4:'Winter'}\n",
        "data = exp['season'].reset_index().copy()\n",
        "data['season'] = data['season'].map(lambda d : season_map[d])\n",
        "\n",
        "data2 = test['season'].reset_index().copy()\n",
        "data2['season'] = data2['season'].map(lambda d : season_map[d])"
      ],
      "metadata": {
        "id": "nDkzFqwSKuSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMCyw-cSLqdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(exp['season'].unique(),exp.groupby('season')['count'].sum())\n"
      ],
      "metadata": {
        "id": "apYrmTRHLV8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the data differ over the two year horizon"
      ],
      "metadata": {
        "id": "0_eI74IoKE_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "sns.boxplot(x='year', y='count', data=exp)\n",
        "plt.ylabel('Count of Users')\n",
        "plt.title(\"Boxplot of Count grouped by year\");"
      ],
      "metadata": {
        "id": "zA6HxvCnH4wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model selection"
      ],
      "metadata": {
        "id": "8GS3TFWbFoji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "metadata": {
        "id": "JopJub3tJWwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rmsle(y_pred, y_actual):\n",
        "    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n",
        "    mean_error = np.square(diff).mean()\n",
        "    return np.sqrt(mean_error)"
      ],
      "metadata": {
        "id": "7nSmx75oMdJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Try running models before adding or modifying features"
      ],
      "metadata": {
        "id": "U4yEzQftFctw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Linear Regression"
      ],
      "metadata": {
        "id": "OlSFluXrF0Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets, linear_model, metrics"
      ],
      "metadata": {
        "id": "OfvdWyA-GQsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = linear_model.LinearRegression()"
      ],
      "metadata": {
        "id": "siFjlmjxGSeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#without feature engineering, can't use time stamp, so select every column after that and before the count columns as predictors\n",
        "#for this initial attempt, I am only going to try to predict the total count, and disregard casual vs registered info all together\n",
        "\n",
        "X=train.iloc[:,1:-3]\n",
        "y=train.iloc[:,-1:]"
      ],
      "metadata": {
        "id": "NwN2-1GxGw6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, test_size=0.3)"
      ],
      "metadata": {
        "id": "dlkde5R9KwuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "BqZ012H6GdT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here are the coefficients of the model\n",
        "\n",
        "print('Coefficients: ', reg.coef_)"
      ],
      "metadata": {
        "id": "sWmNX_i1ISX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=reg.predict(X_valid)"
      ],
      "metadata": {
        "id": "Mo7wT0lGIgI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "kblm3nLDNI2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i3mpvMXqjP7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pretty big rmse\n",
        "\n",
        "rmse(pred, y_valid)"
      ],
      "metadata": {
        "id": "pKVbRN3FJnNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rmsle is pretty far from best models, which get around 0.3\n",
        "\n",
        "get_rmsle(pred, y_valid)"
      ],
      "metadata": {
        "id": "AY00B_WQMhB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest Regression"
      ],
      "metadata": {
        "id": "hwA9Bos0Ft8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "aLbCENIoPjgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_reg= RandomForestRegressor(n_estimators = 100, random_state = 24)"
      ],
      "metadata": {
        "id": "2RNCLSS7GRzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bkJ3RvukM4GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_pred=dt_reg.predict(X_valid)"
      ],
      "metadata": {
        "id": "O8kNHFq0Nrfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_pred=dt_pred.reshape((3266,1))"
      ],
      "metadata": {
        "id": "_mszr_aYN9mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#slightly improved over linear regression\n",
        "\n",
        "rmse(dt_pred, y_valid)"
      ],
      "metadata": {
        "id": "TSN4taePNwjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#also slight improvement but still subpar\n",
        "\n",
        "get_rmsle(dt_pred, y_valid)"
      ],
      "metadata": {
        "id": "jwxPantZOoyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Neural Network"
      ],
      "metadata": {
        "id": "UpWaFH0TQZSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "5L3qCCqNSElT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing required libraries\n",
        "!pip install tensorflow\n",
        "!pip install keras\n"
      ],
      "metadata": {
        "id": "6Cv2021YQcYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "JqvJjFeCR8n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "PredictorScaler=StandardScaler()\n",
        "TargetVarScaler=StandardScaler()"
      ],
      "metadata": {
        "id": "bbE124KdWsTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PredictorScalerFit=PredictorScaler.fit(X)\n",
        "TargetVarScalerFit=TargetVarScaler.fit(y)"
      ],
      "metadata": {
        "id": "Ad-VnVcUWtx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t=PredictorScalerFit.transform(X)\n",
        "y_t=TargetVarScalerFit.transform(y)"
      ],
      "metadata": {
        "id": "Bd_9oKinW-Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X_t, y_t, random_state=42, test_size=0.3)"
      ],
      "metadata": {
        "id": "V_8aeKyGWy7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "BYSHexsfQ_Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(units=5, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "metadata": {
        "id": "S5wvC_BNSCqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train ,batch_size = 20, epochs = 50, verbose=1)"
      ],
      "metadata": {
        "id": "gkoMr6aZSZtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
        "    \n",
        "    # Defining the list of hyper parameters to try\n",
        "    batch_size_list=[5, 10, 15, 20]\n",
        "    epoch_list  =   [5, 10, 50, 100]\n",
        "    \n",
        "    import pandas as pd\n",
        "    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
        "    \n",
        "    # initializing the trials\n",
        "    TrialNumber=0\n",
        "    for batch_size_trial in batch_size_list:\n",
        "        for epochs_trial in epoch_list:\n",
        "            TrialNumber+=1\n",
        "            # create ANN model\n",
        "            model = Sequential()\n",
        "            # Defining the first layer of the model\n",
        "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
        " \n",
        "            # Defining the Second layer of the model\n",
        "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
        " \n",
        "            # The output neuron is a single fully connected node \n",
        "            # Since we will be predicting a single number\n",
        "            model.add(Dense(1, kernel_initializer='normal'))\n",
        " \n",
        "            # Compiling the model\n",
        "            model.compile(loss='mean_squared_logarithmic_error', optimizer=opt, metrics=['mse'])\n",
        " \n",
        "            # Fitting the ANN to the Training set\n",
        "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
        "\n",
        "            RMSLE=get_rmsle(model.predict(X_test), y_test)\n",
        " \n",
        "            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
        "            \n",
        "            # printing the results of the current iteration\n",
        "            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', RMSLE)\n",
        "            \n",
        "            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n",
        "                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n",
        "    return(SearchResultsData)\n",
        " "
      ],
      "metadata": {
        "id": "sbgTWRtkS4dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##batch size of 10 and 10 epochs is best\n",
        "\n",
        "ResultsData=FunctionFindBestParams(X_train, y_train, X_valid, y_valid)"
      ],
      "metadata": {
        "id": "DyWsMBICS6YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "ResultsData.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line')"
      ],
      "metadata": {
        "id": "X3xEXZf_TGl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train ,batch_size = 15, epochs = 50, verbose=1)"
      ],
      "metadata": {
        "id": "v4UyjYSKWGFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions=model.predict(X_valid)"
      ],
      "metadata": {
        "id": "D8HkCNOYWTc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions=TargetVarScalerFit.inverse_transform(Predictions)"
      ],
      "metadata": {
        "id": "pOFP54ZZdB84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid_orig=TargetVarScalerFit.inverse_transform(y_valid)"
      ],
      "metadata": {
        "id": "H6C9gGzRdXro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is slight improvement over random forest\n",
        "\n",
        "rmse(Predictions, y_valid_orig)"
      ],
      "metadata": {
        "id": "-hxKXpB-drR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is somehow worse than random forest\n",
        "\n",
        "get_rmsle(Predictions, y_valid_orig)"
      ],
      "metadata": {
        "id": "Uh1fAsfhdOhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results of various models are pretty mediocre without implementing some feature engineering"
      ],
      "metadata": {
        "id": "qsamss703uYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature engineering"
      ],
      "metadata": {
        "id": "x-HYDrs9P_GC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exp dataframe has been modified to contain things like the hour, day and month as well as the log counts of number of bikes used. It also has datetime in a useable formant"
      ],
      "metadata": {
        "id": "ww0eVp-L38f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp"
      ],
      "metadata": {
        "id": "V3XJZACIKeVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try running the test with the features we have already engineered into exp"
      ],
      "metadata": {
        "id": "sELgKdzr6KZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features=['weather', 'temp', 'atemp', 'windspeed',\n",
        "    'workingday', 'season', 'holiday',\n",
        "    'hour', 'dow', 'woy']\n",
        "exp[features]"
      ],
      "metadata": {
        "id": "Du8Yt7cl40hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=exp[features]\n",
        "y=exp['count']"
      ],
      "metadata": {
        "id": "oqBN7BaK5aoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=42, test_size=0.3)"
      ],
      "metadata": {
        "id": "5wzrbD035N9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_rf=RandomForestRegressor(n_estimators = 100, random_state = 24)"
      ],
      "metadata": {
        "id": "jqz3vyv44r3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HTZ8q_gF360q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds=reg_rf.predict(X_valid)"
      ],
      "metadata": {
        "id": "MXZRop7L5oDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmse(preds, y_valid)"
      ],
      "metadata": {
        "id": "MMprnOCY57l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_rmsle(preds, y_valid)"
      ],
      "metadata": {
        "id": "6GrXDXyy6AVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results are far better than they were before, and even starting to approach state of the art levels"
      ],
      "metadata": {
        "id": "8IlJpoeW6VR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will add some additonal features and refine our testing/training split"
      ],
      "metadata": {
        "id": "3DSIxI8B6e9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add a binary categorical variable peak that is 1 if it is a working day and it is either 8 am or between 17 and 18 pm or if it is a non working day between 10:00 and 19:00\n",
        "\n",
        "exp['peak'] = exp[['hour', 'workingday']]\\\n",
        "    .apply(lambda df: 1 if ((df['workingday'] == 1 and (df['hour'] == 8 or 17 <= df['hour'] <= 18)) \\\n",
        "                            or (df['workingday'] == 0 and 10 <= df['workingday'] <= 19)) else 0, axis = 1)"
      ],
      "metadata": {
        "id": "XCRZX5pn6zFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from histogram\n",
        "#add two more variable, ideal and sticking\n",
        "#ideal is one if it is at least 27 celcius and the windspeed is less than 0\n",
        "#sticky is one if it is a working day and the humidity is above 60\n",
        "\n",
        "exp['ideal'] = exp[['temp', 'windspeed']]\\\n",
        "    .apply(lambda df: 1 if (df['temp'] > 27 and df['windspeed'] < 30) else 0, axis = 1)\n",
        "    \n",
        "exp['sticky'] = exp[['humidity', 'workingday']]\\\n",
        "    .apply(lambda df: 1 if (df['workingday'] == 1 and df['humidity'] >= 60) else 0, axis = 1)"
      ],
      "metadata": {
        "id": "BET16yV97SR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training model"
      ],
      "metadata": {
        "id": "zjiPJ5DkmCl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can't split using the holdout method since we want to predict the last few days of the month using the days previous\n",
        "#the test wants to use the first 20 days to predict the last 10, so for validation we will use the first 15 days as training and the next 4 as validation\n",
        "\n",
        "def custom_valid_split(data, cutoff=15):\n",
        "  train=data[data['day']<=cutoff]\n",
        "  valid=data[data['day']>cutoff]\n",
        "\n",
        "  return train, valid"
      ],
      "metadata": {
        "id": "9lpIiOeW7rts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_train_data(data, input_cols):\n",
        "  X=data[input_cols].values\n",
        "  y_cl=data['casual_log']\n",
        "  y_rl=data['registered_log']\n",
        "\n",
        "  return X, y_cl, y_rl"
      ],
      "metadata": {
        "id": "GV-EJRyK9NcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest"
      ],
      "metadata": {
        "id": "N_tjuDn_mLD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features=[ 'weather', 'temp', 'atemp', 'windspeed',\n",
        "    'workingday', 'season', 'holiday', 'sticky',\n",
        "    'hour', 'dow', 'woy', 'peak']"
      ],
      "metadata": {
        "id": "CoEjvXNY-Pi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data=custom_valid_split(exp)"
      ],
      "metadata": {
        "id": "0eEcTFIA8h2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_cl_train, y_rl_train=prep_train_data(train_data, features)\n",
        "X_val,y_cl_val, y_rl_val=prep_train_data(valid_data, features)"
      ],
      "metadata": {
        "id": "9SHkMPp0-B0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_rf_c=RandomForestRegressor(n_estimators = 100, random_state = 24)"
      ],
      "metadata": {
        "id": "MeeJeFdD-fLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_rf_c.fit(X_train, y_cl_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4dTI2sU-ixM",
        "outputId": "a710953b-d893-4891-d417-569e647b6d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=24)"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert it back from log scale\n",
        "\n",
        "preds_c=np.exp(reg_rf_c.predict(X_val))-1"
      ],
      "metadata": {
        "id": "_i9m-Uv3-m_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_rf_r=RandomForestRegressor(n_estimators = 100, random_state = 24)"
      ],
      "metadata": {
        "id": "TXs4zOYzApj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_rf_r.fit(X_train, y_rl_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T5cOU9q_Rmd",
        "outputId": "8d5e1621-6e77-456b-9b59-7c4233146146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(random_state=24)"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_r=np.exp(reg_rf_r.predict(X_val))-1"
      ],
      "metadata": {
        "id": "i6ah5sZn_2yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_comb = np.round(preds_r + preds_c)\n",
        "y_pred_comb[y_pred_comb < 0] = 0"
      ],
      "metadata": {
        "id": "wzhjiBfdAKY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_actual_comb = np.exp(y_cl_val) + np.exp(y_rl_val) - 2"
      ],
      "metadata": {
        "id": "SOpIaQ8iAyhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Results"
      ],
      "metadata": {
        "id": "hvyzcBZWAGiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_rmsle(y_pred_comb, y_actual_comb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idKZ9khhAzvd",
        "outputId": "d06ad2a0-571d-4360-9df1-bdd2b49ed02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44011142666862885"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse(y_pred_comb, y_actual_comb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTE_lvtAkyL1",
        "outputId": "0f696699-686d-4b4b-f9f3-677710673c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84.45066687485688"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interestingly, after all of that, splitting up the casual and registered users and predicting thier log values seperately actually didnt improve the model. this could however be attributed to the fact that in the previous random forest model, we split using the holdout method, which is not what the problem calls for, so this may have provided overyly optimistic results"
      ],
      "metadata": {
        "id": "y1yOd142Bedk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Neural Network"
      ],
      "metadata": {
        "id": "EiIJuK4XmOMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "since we need to train the model using transformed training data and test it using transformed validation data, we will need to split the model into training and validation first, since the date information that we are splitting on will be lost in the transformation. Then, we will need to transform the training data and then validation data seperately. "
      ],
      "metadata": {
        "id": "Ha6G4Qhn0n8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our method is also to predict the casual riders and registed riders seperately so we will need to train two neural networks, one for each type of user, optimize them seperately, and then combine the predictions and compare them to the actual values from the validation set"
      ],
      "metadata": {
        "id": "57mrj5EN0_Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val=custom_valid_split(exp)"
      ],
      "metadata": {
        "id": "VAhfYECxmfYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_cas_train, y_reg_train=prep_train_data(train, features)\n",
        "X_val,y_cas_val, y_reg_val=prep_train_data(val, features)"
      ],
      "metadata": {
        "id": "VKSU0zqrxlwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "PredictorScaler=StandardScaler()\n",
        "TargetVarScaler=StandardScaler()"
      ],
      "metadata": {
        "id": "E_zZLXmImdg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit Training data\n",
        "\n",
        "#reshape regular and casual values into an array\n",
        "y_cas_train=y_cas_train.values.reshape(8600,1)\n",
        "y_reg_train=y_reg_train.values.reshape(8600,1)\n",
        "\n",
        "#fit X, casual and  registered\n",
        "PredictorScalerFit=PredictorScaler.fit(X_train)\n",
        "TargetVarScalerFit=TargetVarScaler.fit(y_cas_train)\n",
        "TargetVarScalerFit=TargetVarScaler.fit(y_reg_train)\n",
        "\n",
        "X_t=PredictorScalerFit.transform(X_train)\n",
        "y_ct=TargetVarScalerFit.transform(y_cas_train)\n",
        "y_rt=TargetVarScalerFit.transform(y_reg_train)"
      ],
      "metadata": {
        "id": "trfnnlxwmdg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit validation data\n",
        "\n",
        "y_cas_val=y_cas_val.values.reshape(2286,1)\n",
        "y_reg_val=y_reg_val.values.reshape(2286,1)\n",
        "\n",
        "PredictorScalerFit=PredictorScaler.fit(X_val)\n",
        "TargetVarScalerFit=TargetVarScaler.fit(y_cas_val)\n",
        "TargetVarScalerFit=TargetVarScaler.fit(y_reg_val)\n",
        "\n",
        "X_v=PredictorScalerFit.transform(X_val)\n",
        "y_cv=TargetVarScalerFit.transform(y_cas_val)\n",
        "y_rv=TargetVarScalerFit.transform(y_reg_val)"
      ],
      "metadata": {
        "id": "QX6HWYYuzxYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "buid model"
      ],
      "metadata": {
        "id": "mRmQjc_O2Wls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "5R5JvUvZmdg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#neural network with 2 layers, one using relu and one using tanh\n",
        "#learning rate is 0.01\n",
        "#loss function is MSLE\n",
        "\n",
        "model.add(Dense(units=5, input_dim=12, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='normal'))\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='mean_squared_logarithmic_error', optimizer=opt, metrics=['mse'])"
      ],
      "metadata": {
        "id": "1GZntuMcUf_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit model to casual rider data"
      ],
      "metadata": {
        "id": "I-Sm0Wgj2ZG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_t, y_ct ,batch_size = 20, epochs = 50, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09251615-5e1b-4f87-dd9b-a821c5750125",
        "id": "AiI8Tw8kmdg-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0137 - mse: 2.6951\n",
            "Epoch 2/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0136 - mse: 2.6960\n",
            "Epoch 3/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0134 - mse: 2.6933\n",
            "Epoch 4/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0119 - mse: 2.6711\n",
            "Epoch 5/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0093 - mse: 2.5656\n",
            "Epoch 6/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0088 - mse: 2.4631\n",
            "Epoch 7/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0086 - mse: 2.4227\n",
            "Epoch 8/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0085 - mse: 2.4087\n",
            "Epoch 9/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0084 - mse: 2.3863\n",
            "Epoch 10/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0080 - mse: 2.3902\n",
            "Epoch 11/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0077 - mse: 2.3768\n",
            "Epoch 12/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0073 - mse: 2.3799\n",
            "Epoch 13/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0070 - mse: 2.3815\n",
            "Epoch 14/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0066 - mse: 2.3741\n",
            "Epoch 15/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0062 - mse: 2.3860\n",
            "Epoch 16/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0058 - mse: 2.3855\n",
            "Epoch 17/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0054 - mse: 2.4036\n",
            "Epoch 18/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0051 - mse: 2.4021\n",
            "Epoch 19/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0050 - mse: 2.3982\n",
            "Epoch 20/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0048 - mse: 2.3963\n",
            "Epoch 21/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0047 - mse: 2.4020\n",
            "Epoch 22/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0047 - mse: 2.3973\n",
            "Epoch 23/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0047 - mse: 2.4036\n",
            "Epoch 24/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0046 - mse: 2.4078\n",
            "Epoch 25/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0045 - mse: 2.4099\n",
            "Epoch 26/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0045 - mse: 2.4100\n",
            "Epoch 27/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0044 - mse: 2.4137\n",
            "Epoch 28/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0044 - mse: 2.4099\n",
            "Epoch 29/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0044 - mse: 2.4129\n",
            "Epoch 30/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0044 - mse: 2.4109\n",
            "Epoch 31/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0043 - mse: 2.4104\n",
            "Epoch 32/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0043 - mse: 2.4112\n",
            "Epoch 33/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0043 - mse: 2.4125\n",
            "Epoch 34/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0043 - mse: 2.4157\n",
            "Epoch 35/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0043 - mse: 2.4133\n",
            "Epoch 36/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0042 - mse: 2.4167\n",
            "Epoch 37/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0042 - mse: 2.4142\n",
            "Epoch 38/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0042 - mse: 2.4150\n",
            "Epoch 39/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0042 - mse: 2.4196\n",
            "Epoch 40/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0042 - mse: 2.4137\n",
            "Epoch 41/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0041 - mse: 2.4235\n",
            "Epoch 42/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0042 - mse: 2.4441\n",
            "Epoch 43/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0041 - mse: 2.4477\n",
            "Epoch 44/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0039 - mse: 2.4624\n",
            "Epoch 45/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0038 - mse: 2.4634\n",
            "Epoch 46/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0037 - mse: 2.4619\n",
            "Epoch 47/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0037 - mse: 2.4638\n",
            "Epoch 48/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0036 - mse: 2.4631\n",
            "Epoch 49/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0036 - mse: 2.4589\n",
            "Epoch 50/50\n",
            "430/430 [==============================] - 1s 1ms/step - loss: 0.0036 - mse: 2.4619\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f42203f11d0>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimize casual rider hyperparameters"
      ],
      "metadata": {
        "id": "WkF5iqE-2cfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ResultsData=FunctionFindBestParams(X_t, y_ct, X_v, y_cv)"
      ],
      "metadata": {
        "id": "zcwgqGvFtU2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "ResultsData.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line')"
      ],
      "metadata": {
        "id": "VJSgEcB-tU2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimal hyperparameters are 10 batches and 50 epochs"
      ],
      "metadata": {
        "id": "gxUnaQ4_4nPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "refit model using those parameters"
      ],
      "metadata": {
        "id": "cAEhTn4r4tKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_t, y_ct ,batch_size = 10, epochs = 50, verbose=1)"
      ],
      "metadata": {
        "id": "I0jOtnqO4vyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fit model to registered riders"
      ],
      "metadata": {
        "id": "ZpWCh27R2iUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential()"
      ],
      "metadata": {
        "id": "rOGKNjRP5PwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.add(Dense(units=5, input_dim=12, kernel_initializer='normal', activation='relu'))\n",
        "model2.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
        "model2.add(Dense(1, kernel_initializer='normal'))\n",
        "opt = SGD(lr=0.01, momentum=0.9)\n",
        "model2.compile(loss='mean_squared_logarithmic_error', optimizer=opt, metrics=['mse'])"
      ],
      "metadata": {
        "id": "nUL8k-e75PwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_t, y_rt ,batch_size = 20, epochs = 50, verbose=1)"
      ],
      "metadata": {
        "id": "nS9O_6ry2oPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimize registered rider hyperparameters"
      ],
      "metadata": {
        "id": "1O2npqdw2oPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ResultsData2=FunctionFindBestParams(X_t, y_rt, X_v, y_rv)"
      ],
      "metadata": {
        "id": "lNZmIfp42oPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimal Hyperparameters are 20 batches and 50 epochs"
      ],
      "metadata": {
        "id": "vf1DKXNy70Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "ResultsData2.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line')"
      ],
      "metadata": {
        "id": "uYIaQy0m2oPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No need to refit since these were the original hyperparameters"
      ],
      "metadata": {
        "id": "vm78593U5sSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test model"
      ],
      "metadata": {
        "id": "tP4GVAky_Ztw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predict casual and registered riders\n",
        "\n",
        "cas_pred=model.predict(X_v)\n",
        "reg_pred=model2.predict(X_v)"
      ],
      "metadata": {
        "id": "jGEBYh6U84WH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#undo transformation and undo log\n",
        "\n",
        "cas_pred=np.exp(TargetVarScalerFit.inverse_transform(cas_pred))-1\n",
        "reg_pred=np.exp(TargetVarScalerFit.inverse_transform(reg_pred))-1"
      ],
      "metadata": {
        "id": "mABg_iYb-v-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#combine predictions\n",
        "\n",
        "pred_comb=np.round(cas_pred+reg_pred)\n",
        "pred_comb[pred_comb<0]=0"
      ],
      "metadata": {
        "id": "3WACNdc69c5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#retrieve actual values\n",
        "\n",
        "actual_comb = np.exp(y_cas_val) + np.exp(y_reg_val) - 2"
      ],
      "metadata": {
        "id": "D9ZvKMWK99p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Results"
      ],
      "metadata": {
        "id": "P69kNjdvACZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predict\n",
        "#this sucks\n",
        "\n",
        "get_rmsle(pred_comb, actual_comb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3hvfgV6-Ki9",
        "outputId": "3999cd82-52ef-44ef-c7af-2429cd5f4b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2248682197111667"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse(pred_comb, actual_comb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JEo64Nu_5nH",
        "outputId": "da714f9b-7eb4-4221-922a-96e87593c3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110.66753628346308"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After all of that work getting a neural network to run, it looks like the random forest regressor is still far more effective. It is possible that I did the neural network wrong, but I am fairly confident I did all the steps correctly, so Random forest is superior"
      ],
      "metadata": {
        "id": "aVD_VeLS_xMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gradient Boost"
      ],
      "metadata": {
        "id": "7u76saW27iwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
      ],
      "metadata": {
        "id": "zH544mhQ7mzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\n",
        "gbm_model = GradientBoostingRegressor(**params)"
      ],
      "metadata": {
        "id": "f1D0Xvmb8GHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features2 = [\n",
        "    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n",
        "    'holiday', 'workingday', 'season',\n",
        "    'hour', 'dow', 'year', 'ideal'\n",
        "]"
      ],
      "metadata": {
        "id": "ixdLamfA8P5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data=custom_valid_split(exp)"
      ],
      "metadata": {
        "id": "8uFc3Z6U8ct1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_cl_train, y_rl_train=prep_train_data(train_data, features2)\n",
        "X_val,y_cl_val, y_rl_val=prep_train_data(valid_data, features2)"
      ],
      "metadata": {
        "id": "ncVjZ5ju8ct2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbm_model.fit(X_train, y_cl_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEEB6kgi8fIw",
        "outputId": "0023a829-148b-4562-b5f5-d1b0fcef7008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:290: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(loss='ls', max_depth=5, min_samples_leaf=10,\n",
              "                          n_estimators=150, random_state=0, subsample=0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gbm_model2 = GradientBoostingRegressor(**params)\n",
        "gbm_model2.fit(X_train, y_rl_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDFvmY5E8x7k",
        "outputId": "f2b78bc4-9bad-4c52-d09b-fbd867ce0549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:290: FutureWarning: The loss 'ls' was deprecated in v1.0 and will be removed in version 1.2. Use 'squared_error' which is equivalent.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(loss='ls', max_depth=5, min_samples_leaf=10,\n",
              "                          n_estimators=150, random_state=0, subsample=0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cas_preds=np.exp(gbm_model.predict(X_val))-1\n",
        "reg_preds=np.exp(gbm_model2.predict(X_val))-1"
      ],
      "metadata": {
        "id": "m30iXqph8nCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comb=np.round(cas_pred+reg_pred)\n",
        "comb[comb<0]=0"
      ],
      "metadata": {
        "id": "48V8ZwCA8tSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_comb = np.exp(y_cl_val) + np.exp(y_rl_val) - 2"
      ],
      "metadata": {
        "id": "_VCJ00gg9YCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_comb.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUCS71JA-BpO",
        "outputId": "fef08e0d-3796-49ca-f338-a2097c6606d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 39.,  23.,  16., ..., 168., 129.,  88.])"
            ]
          },
          "metadata": {},
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Results"
      ],
      "metadata": {
        "id": "ltcbAAJgDynh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_rmsle(comb, actual_comb.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaL1K4gS9hFJ",
        "outputId": "72675fd5-fcb9-4dbf-e129-f99e2fecbf96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6721735839972827"
            ]
          },
          "metadata": {},
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse(comb, actual_comb.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEoofjbG9l9u",
        "outputId": "851e4123-4c07-4cae-aae3-a6b45744d97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "237.79369374487146"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ]
    }
  ]
}